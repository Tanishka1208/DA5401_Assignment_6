{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3c572c-b35a-4674-9553-822c37a890a7",
   "metadata": {},
   "source": [
    "# A6: Imputation via Regression for Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799ca496-e704-47b4-ba52-27301fe6751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ea85bb-baee-4aa5-8d29-1103795c4cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "631f76b0-238a-4361-bed2-6ec3f8955b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"UCI_Credit_Card.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a481338-ccda-4401-8e04-02d9d3005aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
       "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
       "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
       "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0       0.0       0.0       0.0                           1  \n",
       "1    1000.0       0.0    2000.0                           1  \n",
       "2    1000.0    1000.0    5000.0                           0  \n",
       "3    1100.0    1069.0    1000.0                           0  \n",
       "4    9000.0     689.0     679.0                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631c6bce-9c14-4c6f-8f71-cca30004bc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                            0\n",
       "LIMIT_BAL                     0\n",
       "SEX                           0\n",
       "EDUCATION                     0\n",
       "MARRIAGE                      0\n",
       "AGE                           0\n",
       "PAY_0                         0\n",
       "PAY_2                         0\n",
       "PAY_3                         0\n",
       "PAY_4                         0\n",
       "PAY_5                         0\n",
       "PAY_6                         0\n",
       "BILL_AMT1                     0\n",
       "BILL_AMT2                     0\n",
       "BILL_AMT3                     0\n",
       "BILL_AMT4                     0\n",
       "BILL_AMT5                     0\n",
       "BILL_AMT6                     0\n",
       "PAY_AMT1                      0\n",
       "PAY_AMT2                      0\n",
       "PAY_AMT3                      0\n",
       "PAY_AMT4                      0\n",
       "PAY_AMT5                      0\n",
       "PAY_AMT6                      0\n",
       "default.payment.next.month    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5506ac-c29c-4cca-b08e-07183a2da685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db4ccf8e-811b-43e8-908f-edb405e1804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "AGE          2100\n",
      "BILL_AMT1    2100\n",
      "BILL_AMT2    2100\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "cols_to_nan = ['AGE', 'BILL_AMT1', 'BILL_AMT2']  \n",
    "\n",
    "# Choose fraction of missing data (5–10%)\n",
    "missing_fraction = 0.07  # 7% missing for demo\n",
    "\n",
    "for col in cols_to_nan:\n",
    "    n_missing = int(missing_fraction * len(df))\n",
    "    missing_indices = np.random.choice(df.index, n_missing, replace=False)\n",
    "    df.loc[missing_indices, col] = np.nan\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df[cols_to_nan].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97042602-ce9d-4b2b-80d4-358b44d0085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target column found: default.payment.next.month\n"
     ]
    }
   ],
   "source": [
    "target = 'default.payment.next.month'  # as per UCI dataset column name\n",
    "if target not in df.columns:\n",
    "    print(\"\\n Warning: Target column name might differ — check your CSV header.\")\n",
    "else:\n",
    "    print(\"\\nTarget column found:\", target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0804205f-8a34-4f5e-b289-96297461a09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                               0\n",
       "LIMIT_BAL                        0\n",
       "SEX                              0\n",
       "EDUCATION                        0\n",
       "MARRIAGE                         0\n",
       "AGE                           2100\n",
       "PAY_0                            0\n",
       "PAY_2                            0\n",
       "PAY_3                            0\n",
       "PAY_4                            0\n",
       "PAY_5                            0\n",
       "PAY_6                            0\n",
       "BILL_AMT1                     2100\n",
       "BILL_AMT2                     2100\n",
       "BILL_AMT3                        0\n",
       "BILL_AMT4                        0\n",
       "BILL_AMT5                        0\n",
       "BILL_AMT6                        0\n",
       "PAY_AMT1                         0\n",
       "PAY_AMT2                         0\n",
       "PAY_AMT3                         0\n",
       "PAY_AMT4                         0\n",
       "PAY_AMT5                         0\n",
       "PAY_AMT6                         0\n",
       "default.payment.next.month       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "932ef9c8-4d2b-4c16-8ebb-001e442116a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: ['AGE', 'BILL_AMT1', 'BILL_AMT2']\n",
      "Filled missing values in 'AGE' with median = 34.0\n",
      "Filled missing values in 'BILL_AMT1' with median = 22476.0\n",
      "Filled missing values in 'BILL_AMT2' with median = 21410.5\n",
      "\n",
      "After imputation, number of missing values per column:\n",
      "ID                            0\n",
      "LIMIT_BAL                     0\n",
      "SEX                           0\n",
      "EDUCATION                     0\n",
      "MARRIAGE                      0\n",
      "AGE                           0\n",
      "PAY_0                         0\n",
      "PAY_2                         0\n",
      "PAY_3                         0\n",
      "PAY_4                         0\n",
      "PAY_5                         0\n",
      "PAY_6                         0\n",
      "BILL_AMT1                     0\n",
      "BILL_AMT2                     0\n",
      "BILL_AMT3                     0\n",
      "BILL_AMT4                     0\n",
      "BILL_AMT5                     0\n",
      "BILL_AMT6                     0\n",
      "PAY_AMT1                      0\n",
      "PAY_AMT2                      0\n",
      "PAY_AMT3                      0\n",
      "PAY_AMT4                      0\n",
      "PAY_AMT5                      0\n",
      "PAY_AMT6                      0\n",
      "default.payment.next.month    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanis\\AppData\\Local\\Temp\\ipykernel_12708\\3477227891.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset_A[col].fillna(median_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataset_A = df.copy()\n",
    "\n",
    "missing_cols = dataset_A.columns[dataset_A.isna().any()]\n",
    "print(\"Columns with missing values:\", list(missing_cols))\n",
    "\n",
    "#  Filling missing values using Median Imputation \n",
    "for col in missing_cols:\n",
    "    median_value = dataset_A[col].median()\n",
    "    dataset_A[col].fillna(median_value, inplace=True)\n",
    "    print(f\"Filled missing values in '{col}' with median = {median_value}\")\n",
    "\n",
    "#  Confirm imputation \n",
    "print(\"\\nAfter imputation, number of missing values per column:\")\n",
    "print(dataset_A.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc03bc-7227-47e1-a633-65e8040fb809",
   "metadata": {},
   "source": [
    "Median is often preferred over Mean because it is more robust to outliers.\n",
    "In datasets like credit card client data, columns such as 'AGE' or 'BILL_AMT' often contain skewed distributions ( a few very rich clients or extremely young ones).\n",
    "If mean is used, those outliers will pull the imputed values toward the extremes, distorting the central tendency.\n",
    "The median, however, stays solid. It represents the “middle” of the data and gives a more realistic and stable replacement for missing values in such cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6d29413-d973-41f3-a2b5-cac7b2f63701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanis\\AppData\\Local\\Temp\\ipykernel_12708\\3658065259.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\tanis\\AppData\\Local\\Temp\\ipykernel_12708\\3658065259.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_pred[col].fillna(median_val, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'AGE' after regression imputation: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset_B = df.copy()\n",
    "\n",
    "#  Select target column for regression imputation \n",
    "target_col = 'AGE'\n",
    "\n",
    "# Separate rows where target is missing and not missing\n",
    "missing_mask = dataset_B[target_col].isna()\n",
    "train_data = dataset_B[~missing_mask]\n",
    "predict_data = dataset_B[missing_mask]\n",
    "\n",
    "\n",
    "# Drop target + non-numeric columns\n",
    "X_train = train_data.drop(columns=[target_col, 'default.payment.next.month'], errors='ignore')\n",
    "y_train = train_data[target_col]\n",
    "X_pred = predict_data.drop(columns=[target_col, 'default.payment.next.month'], errors='ignore')\n",
    "\n",
    "# Keep only numeric columns\n",
    "X_train = X_train.select_dtypes(include=[np.number])\n",
    "X_pred = X_pred.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "# Fill remaining NaNs in features with median (so regression can fit)\n",
    "for col in X_train.columns:\n",
    "    median_val = X_train[col].median()\n",
    "    X_train[col].fillna(median_val, inplace=True)\n",
    "    X_pred[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Scale features \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_pred_scaled = scaler.transform(X_pred)\n",
    "\n",
    "# Train Linear Regression model \n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict missing AGE values\n",
    "predicted_ages = reg_model.predict(X_pred_scaled)\n",
    "\n",
    "# Fill missing AGE values back into Dataset B\n",
    "dataset_B.loc[missing_mask, target_col] = predicted_ages\n",
    "\n",
    "print(f\"Number of missing values in '{target_col}' after regression imputation:\",\n",
    "      dataset_B[target_col].isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f70eaa8-600e-46ff-b408-e22ce558f2c6",
   "metadata": {},
   "source": [
    "The Underlying Assumption for Missing At Random (MAR):\n",
    "\n",
    "Regression imputation assumes that the missingness in 'AGE' depends on other observed features, not on 'AGE' itself.\n",
    "\n",
    "Some clients’ 'AGE' is missing because of how the data was collected ( younger users tend to skip entering their age),\n",
    "but we can still predict it using other variables like 'LIMIT_BAL', 'EDUCATION', or 'PAY_0'.\n",
    "\n",
    "That’s what “Missing At Random” means: The probability of missingness depends only on other known data, not the missing value itself.\n",
    "\n",
    "If the data were Not Missing At Random (NMAR), say, older people intentionally hide their age then regression imputation wouldn’t fix that bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90342ca2-af19-470d-be5a-9de89d316be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanis\\AppData\\Local\\Temp\\ipykernel_12708\\3721596559.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\tanis\\AppData\\Local\\Temp\\ipykernel_12708\\3721596559.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_pred[col].fillna(median_val, inplace=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 23)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m     38\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[1;32m---> 39\u001b[0m X_pred_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_pred)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# --- OPTION A: Use K-Nearest Neighbors Regressor ---\u001b[39;00m\n\u001b[0;32m     42\u001b[0m knn_model \u001b[38;5;241m=\u001b[39m KNeighborsRegressor(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\preprocessing\\_data.py:1075\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1072\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1074\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1075\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1077\u001b[0m     X,\n\u001b[0;32m   1078\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1079\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1080\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1081\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m   1082\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1083\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1084\u001b[0m )\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1087\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2952\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2954\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2955\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2956\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1128\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m   1127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m-> 1128\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1129\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1130\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1131\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m   1132\u001b[0m         )\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1135\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 23)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# --- Step 2: Create Dataset C ---\n",
    "dataset_C = df.copy()\n",
    "\n",
    "# --- Step 3: Select target column for imputation ---\n",
    "target_col = 'AGE'\n",
    "\n",
    "# Separate rows where target is missing and not missing\n",
    "missing_mask = dataset_C[target_col].isna()\n",
    "train_data = dataset_C[~missing_mask]\n",
    "predict_data = dataset_C[missing_mask]\n",
    "\n",
    "# --- Step 4: Prepare features ---\n",
    "# Drop target and non-numeric columns\n",
    "X_train = train_data.drop(columns=[target_col, 'default.payment.next.month'], errors='ignore')\n",
    "y_train = train_data[target_col]\n",
    "X_pred = predict_data.drop(columns=[target_col, 'default.payment.next.month'], errors='ignore')\n",
    "\n",
    "# Keep numeric columns\n",
    "X_train = X_train.select_dtypes(include=[np.number])\n",
    "X_pred = X_pred.select_dtypes(include=[np.number])\n",
    "\n",
    "# --- Step 5: Fill NaNs in features (median) ---\n",
    "for col in X_train.columns:\n",
    "    median_val = X_train[col].median()\n",
    "    X_train[col].fillna(median_val, inplace=True)\n",
    "    X_pred[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# --- Step 6: Scale features ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_pred_scaled = scaler.transform(X_pred)\n",
    "\n",
    "# --- OPTION A: Use K-Nearest Neighbors Regressor ---\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "predicted_ages_knn = knn_model.predict(X_pred_scaled)\n",
    "\n",
    "# --- Fill missing values ---\n",
    "dataset_C.loc[missing_mask, target_col] = predicted_ages_knn\n",
    "\n",
    "print(f\"Number of missing values in '{target_col}' after KNN imputation:\",\n",
    "      dataset_C[target_col].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07367933-b2fd-4b81-99ef-dcd846d0bf9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
